{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from layers import disp_to_depth\n",
    "from utils import readlines\n",
    "import datasets\n",
    "import networks\n",
    "import time\n",
    "from thop import profile, clever_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_param(net):\n",
    "    net_params = filter(lambda p: p.requires_grad, net.parameters())\n",
    "    weight_count = 0\n",
    "    for param in net_params:\n",
    "        weight_count += np.prod(param.size())\n",
    "    return weight_count\n",
    "\n",
    "def compute_errors(gt, pred):\n",
    "    \"\"\"Computation of error metrics between predicted and ground truth depths\n",
    "    \"\"\"\n",
    "    thresh = np.maximum((gt / pred), (pred / gt))\n",
    "    a1 = (thresh < 1.25     ).mean()\n",
    "    a2 = (thresh < 1.25 ** 2).mean()\n",
    "    a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "    rmse = (gt - pred) ** 2\n",
    "    rmse = np.sqrt(rmse.mean())\n",
    "\n",
    "    rmse_log = (np.log(gt) - np.log(pred)) ** 2\n",
    "    rmse_log = np.sqrt(rmse_log.mean())\n",
    "\n",
    "    abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "\n",
    "    sq_rel = np.mean(((gt - pred) ** 2) / gt)\n",
    "\n",
    "    return abs_rel, sq_rel, rmse, rmse_log, a1, a2, a3\n",
    "\n",
    "\n",
    "def batch_post_process_disparity(l_disp, r_disp):\n",
    "    \"\"\"Apply the disparity post-processing method as introduced in Monodepthv1\n",
    "    \"\"\"\n",
    "    _, h, w = l_disp.shape\n",
    "    m_disp = 0.5 * (l_disp + r_disp)\n",
    "    l, _ = np.meshgrid(np.linspace(0, 1, w), np.linspace(0, 1, h))\n",
    "    l_mask = (1.0 - np.clip(20 * (l - 0.05), 0, 1))[None, ...]\n",
    "    r_mask = l_mask[:, :, ::-1]\n",
    "    return r_mask * l_disp + l_mask * r_disp + (1.0 - l_mask - r_mask) * m_disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.setNumThreads(0)  # This speeds up evaluation 5x on our unix systems (OpenCV 3.3.1)\n",
    "\n",
    "splits_dir = os.path.join(os.path.expanduser(\"~\"), \"depth\", \"monodepth2\", \"splits\")\n",
    "data_path = \"/work/garin0115/datasets/kitti_data/\"                                \n",
    "# Models which were trained with stereo supervision were trained with a nominal\n",
    "# baseline of 0.1 units. The KITTI rig has a baseline of 54cm. Therefore,\n",
    "# to convert our stereo predictions to real-world scale we multiply our depths by 5.4.\n",
    "STEREO_SCALE_FACTOR = 5.4\n",
    "post_process = False\n",
    "ext_disp_to_eval = None\n",
    "eval_split = \"eigen\"\n",
    "eval_stereo = False\n",
    "MIN_DEPTH = 1e-3\n",
    "MAX_DEPTH = 80\n",
    "disable_median_scaling = False\n",
    "pred_depth_scale_factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dict = {\"resnet18\":networks.ResnetEncoder(18, False)}\n",
    "# dec_dict = {    \"resnet18\":networks.DepthDecoder(enc_dict[\"resnet18\"].num_ch_enc),\n",
    "#                 \"resnet18_nn3\":networks.NNDecoder(\n",
    "#                     enc_dict[\"resnet18\"].num_ch_enc, kernel_size=3, dw=False),\n",
    "#                 \"resnet18_nn3_dw\":networks.NNDecoder(\n",
    "#                     enc_dict[\"resnet18\"].num_ch_enc, kernel_size=3, dw=True),\n",
    "#                 \"resnet18_nn5\":networks.NNDecoder(\n",
    "#                     enc_dict[\"resnet18\"].num_ch_enc, kernel_size=5, dw=False),\n",
    "#                 \"resnet18_nn5_dw\":networks.NNDecoder(\n",
    "#                     enc_dict[\"resnet18\"].num_ch_enc, kernel_size=5, dw=True),\n",
    "#                 \"resnet18_nn35\":networks.NNDecoder(\n",
    "#                     enc_dict[\"resnet18\"].num_ch_enc, kernel_size=35, dw=False),\n",
    "#                 \"resnet18_nn53\":networks.NNDecoder(\n",
    "#                     enc_dict[\"resnet18\"].num_ch_enc, kernel_size=53, dw=False),\n",
    "#                 \"resnet18_nn3_3x3\":networks.NNDecoder(\n",
    "#                     enc_dict[\"resnet18\"].num_ch_enc, kernel_size=3, dw=False, pw=3),\n",
    "#                 \"resnet18_nn3_upconv\":networks.NNDecoder(\n",
    "#                     enc_dict[\"resnet18\"].num_ch_enc, kernel_size=3, dw=False, upconv=True)}\n",
    "# dec_dict = {\"resnet18_my3\":networks.MYDecoder(enc_dict[\"resnet18\"].num_ch_enc),\n",
    "#             \"resnet18_my3_more1\":networks.MYDecoder(enc_dict[\"resnet18\"].num_ch_enc, moreConv=1),\n",
    "#             \"resnet18_my3_more2\":networks.MYDecoder(enc_dict[\"resnet18\"].num_ch_enc, moreConv=2),\n",
    "#             \"resnet18_my3_concatDepth\":networks.MYDecoder(enc_dict[\"resnet18\"].num_ch_enc, concatDepth=True),\n",
    "#             \"resnet18_my3_doubleConv1\":networks.MYDecoder(enc_dict[\"resnet18\"].num_ch_enc, doubleConv=1),\n",
    "#             \"resnet18_my3_doubleConv3\":networks.MYDecoder(enc_dict[\"resnet18\"].num_ch_enc, doubleConv=3),\n",
    "#             \"resnet18_my3_doubleConv3_3x3\":networks.MYDecoder(enc_dict[\"resnet18\"].num_ch_enc, doubleConv=3, pw=False),\n",
    "#             \"resnet18_my3_firstConv\":networks.MYDecoder(enc_dict[\"resnet18\"].num_ch_enc, firstConv=True),\n",
    "#             \"resnet18_my3_skipSky\":networks.MYDecoder(enc_dict[\"resnet18\"].num_ch_enc),\n",
    "#             \"resnet18_my3_firstConv_skipSky\":networks.MYDecoder(enc_dict[\"resnet18\"].num_ch_enc, firstConv=True),\n",
    "#             \"resnet18_my3_smooth\":networks.MYDecoder(enc_dict[\"resnet18\"].num_ch_enc),\n",
    "#             \"resnet18_my3_firstConv_skipSky_conv11\":networks.MYDecoder(enc_dict[\"resnet18\"].num_ch_enc, firstConv=True, conv11=True)}\n",
    "# dec_dict = {\"resnet18\":networks.DepthDecoder(enc_dict[\"resnet18\"].num_ch_enc),\n",
    "# #                 \"resnet18_nn3\":networks.NNDecoder(\n",
    "# #                     encoder_dict[\"resnet18\"].num_ch_enc, kernel_size=3, dw=False),\n",
    "# #                 \"resnet18_my3\":networks.MYDecoder(\n",
    "# #                     encoder_dict[\"resnet18\"].num_ch_enc, kernel_size=3, dw=False),\n",
    "# #                 \"resnet18_my3_dw\":networks.MYDecoder(\n",
    "# #                     enc_dict[\"resnet18\"].num_ch_enc, kernel_size=3, dw=True),\n",
    "#                 \"resnet18_my35_nomask\":networks.MYDecoder(\n",
    "#                     enc_dict[\"resnet18\"].num_ch_enc, kernel_size=35, dw=False),\n",
    "# #                 \"resnet18_my3_3x3\":networks.MYDecoder(\n",
    "# #                     enc_dict[\"resnet18\"].num_ch_enc, kernel_size=3, dw=False, pw=3),\n",
    "#                 \"resnet18_my35_more\":networks.MYDecoder(\n",
    "#                     enc_dict[\"resnet18\"].num_ch_enc, kernel_size=35, dw=False, more=True)}\n",
    "dec_dict = {\n",
    "    \"resnet18_skipFirstConv\":networks.DepthDecoder(enc_dict[\"resnet18\"].num_ch_enc, skipFirstConv=True),\n",
    "    \"resnet18_skipFirstConv_skipSky\":networks.DepthDecoder(enc_dict[\"resnet18\"].num_ch_enc, skipFirstConv=True),\n",
    "    \"resnet18_my3_skipSky\":networks.MYDecoder(enc_dict[\"resnet18\"].num_ch_enc),\n",
    "    \"resnet18_my3\":networks.MYDecoder(enc_dict[\"resnet18\"].num_ch_enc),\n",
    "    \"resnet18_skip2Conv\":networks.DepthDecoder(enc_dict[\"resnet18\"].num_ch_enc, skip2Conv=True),\n",
    "    \"resnet18_skipFirstConv\":networks.DepthDecoder(enc_dict[\"resnet18\"].num_ch_enc, skipFirstConv=True),\n",
    "}\n",
    "               \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Loading weights from /home/garin0115/depth/monodepth2/models/resnet18_skipFirstConv_256x832/models/weights_19\n",
      "[info] Model resnet18_skipFirstConv\n",
      "[info] Encoder parameter count: 11689512\n",
      "[info] Decoder parameter count: 3742548\n",
      "[info] Total parameter count: 15432060\n",
      "-> Computing predictions with size 832x256\n",
      "-> Evaluating\n",
      "   Mono evaluation - using median scaling\n",
      " Scaling ratios | med: 3001.452 | std: 0.083\n",
      "[info] resnet18_skipFirstConv\n",
      " FPS:  282.5969545883304\n",
      "\n",
      "   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 | \n",
      "&   0.115  &   0.896  &   4.846  &   0.194  &   0.878  &   0.960  &   0.981  \\\\\n",
      "\n",
      "-> Done!\n",
      "-> Loading weights from /home/garin0115/depth/monodepth2/models/resnet18_skipFirstConv_skipSky_256x832/models/weights_19\n",
      "[info] Model resnet18_skipFirstConv_skipSky\n",
      "[info] Encoder parameter count: 11689512\n",
      "[info] Decoder parameter count: 3742548\n",
      "[info] Total parameter count: 15432060\n",
      "-> Computing predictions with size 832x256\n",
      "-> Evaluating\n",
      "   Mono evaluation - using median scaling\n",
      " Scaling ratios | med: 2788.895 | std: 0.084\n",
      "[info] resnet18_skipFirstConv_skipSky\n",
      " FPS:  267.05106328791544\n",
      "\n",
      "   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 | \n",
      "&   0.114  &   0.861  &   4.741  &   0.190  &   0.880  &   0.961  &   0.982  \\\\\n",
      "\n",
      "-> Done!\n",
      "-> Loading weights from /home/garin0115/depth/monodepth2/models/resnet18_my3_skipSky_256x832/models/weights_29\n",
      "[info] Model resnet18_my3_skipSky\n",
      "[info] Encoder parameter count: 11689512\n",
      "[info] Decoder parameter count: 2365136\n",
      "[info] Total parameter count: 14054648\n",
      "-> Computing predictions with size 832x256\n",
      "-> Evaluating\n",
      "   Mono evaluation - using median scaling\n",
      " Scaling ratios | med: 3660.534 | std: 0.082\n",
      "[info] resnet18_my3_skipSky\n",
      " FPS:  302.2703949264918\n",
      "\n",
      "   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 | \n",
      "&   0.116  &   0.921  &   4.864  &   0.192  &   0.879  &   0.960  &   0.981  \\\\\n",
      "\n",
      "-> Done!\n",
      "-> Loading weights from /work/garin0115/models/resnet18_my3_256x832/models/weights_29\n",
      "[info] Model resnet18_my3\n",
      "[info] Encoder parameter count: 11689512\n",
      "[info] Decoder parameter count: 2365136\n",
      "[info] Total parameter count: 14054648\n",
      "-> Computing predictions with size 832x256\n",
      "-> Evaluating\n",
      "   Mono evaluation - using median scaling\n",
      " Scaling ratios | med: 3730.438 | std: 0.083\n",
      "[info] resnet18_my3\n",
      " FPS:  300.94740618497525\n",
      "\n",
      "   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 | \n",
      "&   0.115  &   0.857  &   4.759  &   0.191  &   0.878  &   0.960  &   0.982  \\\\\n",
      "\n",
      "-> Done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Evaluates a pretrained model using a specified test set\n",
    "\"\"\"\n",
    "results = []\n",
    "inWork = [\"resnet18_my3\", \"resnet18_my3_more1\", \"resnet18_my3_more2\", \"resnet18_my3_concatDepth\", \"resnet18_my3_doubleConv1\", \"resnet18_my3_doubleConv3\"]\n",
    "fineTune = [\"resnet18_my3\", \"resnet18_my3_skipSky\"]\n",
    "for name in dec_dict:\n",
    "    if name in inWork:\n",
    "        load_weights_folder = os.path.join(\"/work\", \"garin0115\", \"models\", name+\"_256x832\", \"models\")\n",
    "    else:\n",
    "        load_weights_folder = os.path.join(os.path.expanduser(\"~\"), \n",
    "                                       \"depth\", \n",
    "                                       \"monodepth2\",\n",
    "                                       \"models\", \n",
    "                                       name+\"_256x832\", \n",
    "                                       \"models\")\n",
    "    if name in fineTune:\n",
    "        load_weights_folder = os.path.join(load_weights_folder, \"weights_29\")\n",
    "    else:\n",
    "        load_weights_folder = os.path.join(load_weights_folder, \"weights_19\")\n",
    "    \n",
    "    assert os.path.isdir(load_weights_folder), \\\n",
    "        \"Cannot find a folder at {}\".format(load_weights_folder)\n",
    "\n",
    "    print(\"-> Loading weights from {}\".format(load_weights_folder))\n",
    "\n",
    "    filenames = readlines(os.path.join(splits_dir, eval_split, \"test_files.txt\"))\n",
    "    encoder_path = os.path.join(load_weights_folder, \"encoder.pth\")\n",
    "    decoder_path = os.path.join(load_weights_folder, \"depth.pth\")\n",
    "\n",
    "    encoder_dict = torch.load(encoder_path)\n",
    "\n",
    "    dataset = datasets.KITTIRAWDataset(data_path, filenames,\n",
    "                                       encoder_dict['height'], encoder_dict['width'],\n",
    "                                       [0], 4, is_train=False)\n",
    "    dataloader = DataLoader(dataset, 16, shuffle=False, num_workers=16,\n",
    "                            pin_memory=True, drop_last=False)\n",
    "\n",
    "    encoder = enc_dict[\"resnet18\"]\n",
    "    depth_decoder = dec_dict[name]\n",
    "\n",
    "    enc_param_count = calc_param(encoder)\n",
    "    dec_param_count = calc_param(depth_decoder)\n",
    "    print(\"[info] Model {}\".format(name))\n",
    "    print(\"[info] Encoder parameter count:\", enc_param_count)\n",
    "    print(\"[info] Decoder parameter count:\", dec_param_count)\n",
    "    print(\"[info] Total parameter count:\", enc_param_count + dec_param_count)\n",
    "\n",
    "    model_dict = encoder.state_dict()\n",
    "    encoder.load_state_dict({k: v for k, v in encoder_dict.items() if k in model_dict})\n",
    "    depth_decoder.load_state_dict(torch.load(decoder_path))\n",
    "\n",
    "    encoder.cuda()\n",
    "    encoder.eval()\n",
    "    depth_decoder.cuda()\n",
    "    depth_decoder.eval()\n",
    "\n",
    "    pred_disps = []\n",
    "\n",
    "    print(\"-> Computing predictions with size {}x{}\".format(\n",
    "        encoder_dict['width'], encoder_dict['height']))\n",
    "    \n",
    "    time_min = 10000\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data in dataloader:\n",
    "            start_time = time.time()\n",
    "            input_color = data[(\"color\", 0, 0)].cuda()\n",
    "\n",
    "            if post_process:\n",
    "                # Post-processed results require each image to have two forward passes\n",
    "                input_color = torch.cat((input_color, torch.flip(input_color, [3])), 0)\n",
    "            start_time = time.time()\n",
    "            features = encoder(input_color)\n",
    "            output = depth_decoder(features)\n",
    "            total_time = time.time() - start_time\n",
    "            pred_disp, _ = disp_to_depth(output[(\"disp\", 0)], MIN_DEPTH, MAX_DEPTH)\n",
    "            pred_disp = pred_disp.cpu()[:, 0].numpy()\n",
    "    #                 pred_disp = pred_disp[:, 0].numpy()\n",
    "\n",
    "            if post_process:\n",
    "                N = pred_disp.shape[0] // 2\n",
    "                pred_disp = batch_post_process_disparity(pred_disp[:N], pred_disp[N:, :, ::-1])\n",
    "\n",
    "            pred_disps.append(pred_disp)\n",
    "            \n",
    "            if total_time < time_min:\n",
    "                time_min = total_time\n",
    "                \n",
    "    pred_disps = np.concatenate(pred_disps)\n",
    "\n",
    "\n",
    "    gt_path = os.path.join(splits_dir, eval_split, \"gt_depths.npz\")\n",
    "    gt_depths = np.load(gt_path, fix_imports=True, encoding='latin1', allow_pickle=True)[\"data\"]\n",
    "    #     gt_depths = np.load(gt_path)[\"data\"]\n",
    "\n",
    "    print(\"-> Evaluating\")\n",
    "\n",
    "    if eval_stereo:\n",
    "        print(\"   Stereo evaluation - \"\n",
    "              \"disabling median scaling, scaling by {}\".format(STEREO_SCALE_FACTOR))\n",
    "        disable_median_scaling = True\n",
    "        pred_depth_scale_factor = STEREO_SCALE_FACTOR\n",
    "    else:\n",
    "        print(\"   Mono evaluation - using median scaling\")\n",
    "\n",
    "    errors = []\n",
    "    ratios = []\n",
    "\n",
    "    for i in range(pred_disps.shape[0]):\n",
    "\n",
    "        gt_depth = gt_depths[i]\n",
    "        gt_height, gt_width = gt_depth.shape[:2]\n",
    "\n",
    "        pred_disp = pred_disps[i]\n",
    "        pred_disp = cv2.resize(pred_disp, (gt_width, gt_height))\n",
    "        pred_depth = 1 / pred_disp\n",
    "\n",
    "        if eval_split == \"eigen\":\n",
    "            mask = np.logical_and(gt_depth > MIN_DEPTH, gt_depth < MAX_DEPTH)\n",
    "\n",
    "            crop = np.array([0.40810811 * gt_height, 0.99189189 * gt_height,\n",
    "                             0.03594771 * gt_width,  0.96405229 * gt_width]).astype(np.int32)\n",
    "            crop_mask = np.zeros(mask.shape)\n",
    "            crop_mask[crop[0]:crop[1], crop[2]:crop[3]] = 1\n",
    "            mask = np.logical_and(mask, crop_mask)\n",
    "\n",
    "        else:\n",
    "            mask = gt_depth > 0\n",
    "\n",
    "        pred_depth = pred_depth[mask]\n",
    "        gt_depth = gt_depth[mask]\n",
    "\n",
    "        pred_depth *= pred_depth_scale_factor\n",
    "        if not disable_median_scaling:\n",
    "            ratio = np.median(gt_depth) / np.median(pred_depth)\n",
    "            ratios.append(ratio)\n",
    "            pred_depth *= ratio\n",
    "\n",
    "        pred_depth[pred_depth < MIN_DEPTH] = MIN_DEPTH\n",
    "        pred_depth[pred_depth > MAX_DEPTH] = MAX_DEPTH\n",
    "\n",
    "        errors.append(compute_errors(gt_depth, pred_depth))\n",
    "\n",
    "    if not disable_median_scaling:\n",
    "        ratios = np.array(ratios)\n",
    "        med = np.median(ratios)\n",
    "        print(\" Scaling ratios | med: {:0.3f} | std: {:0.3f}\".format(med, np.std(ratios / med)))\n",
    "\n",
    "    mean_errors = np.array(errors).mean(0)\n",
    "    print(\"[info] {}\".format(name))\n",
    "    print(\" FPS: \", 1/time_min)\n",
    "    print(\"\\n  \" + (\"{:>8} | \" * 7).format(\"abs_rel\", \"sq_rel\", \"rmse\", \"rmse_log\", \"a1\", \"a2\", \"a3\"))\n",
    "    print((\"&{: 8.3f}  \" * 7).format(*mean_errors.tolist()) + \"\\\\\\\\\")\n",
    "    print(\"\\n-> Done!\")\n",
    "    \n",
    "\n",
    "    flops_enc, params_enc = profile(encoder, inputs=(input_color, ))\n",
    "    flops_dec, params_dec = profile(depth_decoder, inputs=(features, ))\n",
    "    a, b, c, d, e, f = clever_format([params_enc+params_dec, params_enc, params_dec, flops_enc+flops_dec, flops_enc, flops_dec], \"%.3f\")\n",
    "    \n",
    "    result = []\n",
    "    result.append(name)\n",
    "    result.append(encoder_dict['height'])\n",
    "    result.append(encoder_dict['width'])\n",
    "    for i in mean_errors:\n",
    "        result.append(i)\n",
    "    result.append(1/time_min)\n",
    "    for i in [a, b, c, d, e, f]:\n",
    "        result.append(i)\n",
    "    results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# 開啟輸出的 CSV 檔案\n",
    "with open('result.csv', 'w', newline='') as csvfile:\n",
    "    # 建立 CSV 檔寫入器\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # 寫入一列資料\n",
    "    writer.writerow(['Model', 'Height', 'Width', \"abs_rel\", \"sq_rel\", \"rmse\", \"rmse_log\", \"a1\", \"a2\", \"a3\", \n",
    "                  'FPS', 'Parameters', 'params_enc', 'params_dec', 'FLOPs', 'fl_enc', 'fl_dec'])\n",
    "\n",
    "    # 寫入另外幾列資料\n",
    "    for res in results:\n",
    "        writer.writerow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
