{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch2trt import torch2trt\n",
    "from torchvision.models.alexnet import alexnet\n",
    "\n",
    "# create some regular pytorch model...\n",
    "model = alexnet(pretrained=True).eval().cuda()\n",
    "\n",
    "# create example data\n",
    "x = torch.ones((1, 3, 224, 224)).cuda()\n",
    "\n",
    "# convert to TensorRT feeding sample data as input\n",
    "model_trt = torch2trt(model, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x)\n",
    "y_trt = model_trt(x)\n",
    "\n",
    "# check the output against PyTorch\n",
    "print(torch.max(torch.abs(y - y_trt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch2trt import *\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "from layers import disp_to_depth\n",
    "from utils import readlines\n",
    "import datasets\n",
    "import networks\n",
    "import time\n",
    "from thop import profile, clever_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet18\"\n",
    "load_weights_folder = os.path.join(\"/work\", \"garin0115\", \"models\", model_name+\"_256x832\", \"models\", \"weights_19\")\n",
    "\n",
    "encoder_path = os.path.join(load_weights_folder, \"encoder.pth\")\n",
    "decoder_path = os.path.join(load_weights_folder, \"depth.pth\")\n",
    "encoder_pth = torch.load(encoder_path)\n",
    "decoder_pth = torch.load(decoder_path)\n",
    "encoder = networks.ResnetEncoder(18, False)\n",
    "decoder = networks.DepthDecoder(encoder.num_ch_enc)\n",
    "encoder.load_state_dict({k: v for k, v in encoder_pth.items() if k in encoder.state_dict()})\n",
    "decoder.load_state_dict(decoder_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder.eval()\n",
    "encoder.cuda()\n",
    "# decoder.eval()\n",
    "# decoder.cuda()\n",
    "\n",
    "\n",
    "# create example data\n",
    "x = torch.ones((1, 3, 256, 832)).cuda()\n",
    "\n",
    "\n",
    "x0 = torch.ones((1, 64, 128, 416)).cuda()\n",
    "x1 = torch.ones((1, 64, 64, 208)).cuda()\n",
    "x2 = torch.ones((1, 128, 32, 104)).cuda()\n",
    "x3 = torch.ones((1, 256, 16, 52)).cuda()\n",
    "x4 = torch.ones((1, 512, 8, 26)).cuda()\n",
    "\n",
    "# convert to TensorRT feeding sample data as input\n",
    "encoder_trt = torch2trt(encoder, [x])\n",
    "encoder_trt.eval()\n",
    "# decoder_trt = torch2trt(decoder, [x0, x1, x2, x3, x4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = time.time()\n",
    "y_trt = encoder_trt(x)\n",
    "FPS_trt = 1/(time.time()-t2)\n",
    "t1 = time.time()\n",
    "y = encoder(x)\n",
    "FPS = 1/(time.time()-t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for yi, yi_trt in zip(y, y_trt):\n",
    "    print(torch.max(torch.abs(yi - yi_trt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FPS, FPS_trt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trt.__path__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ONNX to TRT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
    "\n",
    "def build_engine(onnx_path, shape = [1,3,256,832]):\n",
    "\n",
    "    \"\"\"\n",
    "    This is the function to create the TensorRT engine\n",
    "    Args:\n",
    "      onnx_path : Path to onnx_file. \n",
    "      shape : Shape of the input of the ONNX file. \n",
    "    \"\"\"\n",
    "    network_flags = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "    with trt.Builder(TRT_LOGGER) as builder, builder.create_network(network_flags) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "        builder.max_workspace_size = (1 << 30)\n",
    "        with open(onnx_path, 'rb') as model:\n",
    "            if not parser.parse(model.read()):\n",
    "                print('ERROR: Failed to parse the ONNX file.')\n",
    "                for error in range(parser.num_errors):\n",
    "                    print(parser.get_error(error))\n",
    "            res = parser.parse(model.read())\n",
    "            print(res)\n",
    "        network.get_input(0).shape = shape\n",
    "        engine = builder.build_cuda_engine(network)\n",
    "        return engine\n",
    "\n",
    "def save_engine(engine, file_name):\n",
    "    buf = engine.serialize()\n",
    "    with open(file_name, 'wb') as f:\n",
    "        f.write(buf)\n",
    "        \n",
    "def load_engine(trt_runtime, plan_path):\n",
    "    with open(plan_path, 'rb') as f:\n",
    "        engine_data = f.read()\n",
    "    engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from onnx import ModelProto\n",
    "import tensorrt as trt\n",
    "import os\n",
    "\n",
    "engine_name = \"resnet18_skyLoss.plan\"\n",
    "onnx_path = os.path.join(\"/work\", \"garin0115\", \"models\", \"resnet18_skyLoss_256x832\", \"models\", \"weights_19\", \"resnet18_skyLoss.onnx\")\n",
    "batch_size = 1 \n",
    "\n",
    "model = ModelProto()\n",
    "with open(onnx_path, \"rb\") as f:\n",
    "    model.ParseFromString(f.read())\n",
    "\n",
    "d0 = model.graph.input[0].type.tensor_type.shape.dim[1].dim_value\n",
    "d1 = model.graph.input[0].type.tensor_type.shape.dim[2].dim_value\n",
    "d2 = model.graph.input[0].type.tensor_type.shape.dim[3].dim_value\n",
    "shape = [batch_size , d0, d1 ,d2]\n",
    "engine = build_engine(onnx_path, shape=shape)\n",
    "save_engine(engine, engine_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_load = load_engine(trt_runtime, engine_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch2trt import *\n",
    "from module_test import ModuleTest, MODULE_TESTS\n",
    "import time\n",
    "import argparse\n",
    "import re\n",
    "import runpy\n",
    "from termcolor import colored\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "\n",
    "def run(self):\n",
    "    # create module\n",
    "    module = self.module_fn()\n",
    "    module = module.to(self.device)\n",
    "    module = module.type(self.dtype)\n",
    "    module = module.eval()\n",
    "    \n",
    "    # create inputs for conversion\n",
    "    inputs_conversion = ()\n",
    "    for shape in self.input_shapes:\n",
    "        inputs_conversion += (torch.zeros(shape).to(self.device).type(self.dtype), )\n",
    "        \n",
    "    # convert module\n",
    "    module_trt = torch2trt(module, inputs_conversion, **self.torch2trt_kwargs)\n",
    "\n",
    "    # create inputs for torch/trt.. copy of inputs to handle inplace ops\n",
    "    inputs = ()\n",
    "    for shape in self.input_shapes:\n",
    "        inputs += (torch.randn(shape).to(self.device).type(self.dtype), )\n",
    "    inputs_trt = tuple([tensor.clone() for tensor in inputs])\n",
    "\n",
    "\n",
    "    # test output against original\n",
    "    outputs = module(*inputs)\n",
    "    outputs_trt = module_trt(*inputs_trt)\n",
    "\n",
    "    if not isinstance(outputs, tuple):\n",
    "        outputs = (outputs, )\n",
    "    \n",
    "    # compute max error\n",
    "    max_error = 0\n",
    "    for i in range(len(outputs)):\n",
    "        max_error_i = torch.max(torch.abs(outputs[i] - outputs_trt[i]))\n",
    "        if max_error_i > max_error:\n",
    "            max_error = max_error_i\n",
    "    \n",
    "    # benchmark pytorch throughput\n",
    "    torch.cuda.current_stream().synchronize()\n",
    "    t0 = time.time()\n",
    "    for i in range(50):\n",
    "        outputs = module(*inputs)\n",
    "    torch.cuda.current_stream().synchronize()\n",
    "    t1 = time.time()\n",
    "    \n",
    "    fps = 50.0 / (t1 - t0)\n",
    "    \n",
    "    # benchmark tensorrt throughput\n",
    "    torch.cuda.current_stream().synchronize()\n",
    "    t0 = time.time()\n",
    "    for i in range(50):\n",
    "        outputs = module_trt(*inputs)\n",
    "    torch.cuda.current_stream().synchronize()\n",
    "    t1 = time.time()\n",
    "    \n",
    "    fps_trt = 50.0 / (t1 - t0)\n",
    "    \n",
    "    # benchmark pytorch latency\n",
    "    torch.cuda.current_stream().synchronize()\n",
    "    t0 = time.time()\n",
    "    for i in range(50):\n",
    "        outputs = module(*inputs)\n",
    "        torch.cuda.current_stream().synchronize()\n",
    "    t1 = time.time()\n",
    "    \n",
    "    ms = 1000.0 * (t1 - t0) / 50.0\n",
    "    \n",
    "    # benchmark tensorrt latency\n",
    "    torch.cuda.current_stream().synchronize()\n",
    "    t0 = time.time()\n",
    "    for i in range(50):\n",
    "        outputs = module_trt(*inputs)\n",
    "        torch.cuda.current_stream().synchronize()\n",
    "    t1 = time.time()\n",
    "    \n",
    "    ms_trt = 1000.0 * (t1 - t0) / 50.0\n",
    "    \n",
    "    return max_error, fps, fps_trt, ms, ms_trt\n",
    "        \n",
    "        \n",
    "    \n",
    "for include in []:\n",
    "    runpy.run_module(include)\n",
    "\n",
    "for test in MODULE_TESTS:\n",
    "\n",
    "    # filter by module name\n",
    "    name = test.module_name()\n",
    "    if not re.search('interpolate', name):\n",
    "        continue\n",
    "\n",
    "    # run test\n",
    "    max_error, fps, fps_trt, ms, ms_trt = run(test)\n",
    "\n",
    "    # write entry\n",
    "    line = '| %s | %s | %s | %s | %.2E | %.3g | %.3g | %.3g | %.3g |' % (name, test.dtype.__repr__().split('.')[-1], str(test.input_shapes), str(test.torch2trt_kwargs), max_error, fps, fps_trt, ms, ms_trt)\n",
    "\n",
    "    print(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
