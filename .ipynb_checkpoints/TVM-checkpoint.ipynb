{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import te\n",
    "import tvm.relay as relay\n",
    "from tvm.contrib.download import download_testdata\n",
    "import os\n",
    "import PIL.Image as pil\n",
    "import networks\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Depth(nn.Module):\n",
    "    def __init__(self, encoder, decoder, output_list=False):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.output_list = output_list\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        feature = self.encoder(inputs)\n",
    "        output = self.decoder(*tuple(feature))\n",
    "        if self.output_list:\n",
    "            list_output = []\n",
    "            for key, value in output.items():\n",
    "                list_output.append(value)\n",
    "            output = list_output\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet18\"\n",
    "load_weights_folder = os.path.join(\"/work\", \"garin0115\", \"models\", model_name+\"_256x832\", \"models\", \"weights_19\")\n",
    "\n",
    "encoder_path = os.path.join(load_weights_folder, \"encoder.pth\")\n",
    "decoder_path = os.path.join(load_weights_folder, \"depth.pth\")\n",
    "encoder_pth = torch.load(encoder_path)\n",
    "decoder_pth = torch.load(decoder_path)\n",
    "encoder = networks.ResnetEncoder(18, False)\n",
    "decoder = networks.DepthDecoder(encoder.num_ch_enc)\n",
    "encoder.load_state_dict({k: v for k, v in encoder_pth.items() if k in encoder.state_dict()})\n",
    "decoder.load_state_dict(decoder_pth)\n",
    "model = Depth(encoder, decoder, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [1, 3, 256, 832]\n",
    "input_data = torch.randn(input_shape)\n",
    "scripted_model = torch.jit.trace(model, input_data).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"assets/test_image.jpg\"\n",
    "input_image = pil.open(image_path).convert('RGB')\n",
    "original_width, original_height = input_image.size\n",
    "input_image_resized = input_image.resize((832, 256), pil.LANCZOS)\n",
    "input_image_torch = transforms.ToTensor()(input_image_resized).unsqueeze(0)\n",
    "# input_image_torch = input_image_torch.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = 'input0'\n",
    "shape_list = [(input_name, input_image_torch.shape)]\n",
    "mod, params = relay.frontend.from_pytorch(scripted_model,\n",
    "                                          shape_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(\"/work\", \n",
    "                          \"garin0115\", \n",
    "                          \"models\", \n",
    "                          \"resnet18_256x832\", \n",
    "                          \"models\", \n",
    "                          \"weights_19\", \n",
    "                          \"resnet18.onnx\")\n",
    "onnx_model = onnx.load(model_path)\n",
    "\n",
    "x = np.ones([1,3,256,832])\n",
    "# arch = \"arm64\"\n",
    "# target =  \"llvm -target=%s-linux-android\" % arch\n",
    "target = 'llvm'\n",
    "input_name = 'gemfield'\n",
    "shape_dict = {input_name: x.shape}\n",
    "sym, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n",
    "\n",
    "with relay.build_config(opt_level=1):\n",
    "    intrp = relay.build_module.create_executor('graph', sym, tvm.cpu(0), target)\n",
    "\n",
    "dtype = 'float32'\n",
    "tvm_output = intrp.evaluate(sym)(tvm.nd.array(x.astype(dtype)), **params).asnumpy()\n",
    "\n",
    "with relay.build_config(opt_level=2):\n",
    "    graph, lib, params = relay.build_module.build(sym, target, params=params)\n",
    "\n",
    "libpath = \"gemfield.so\"\n",
    "lib.export_library(libpath)\n",
    "\n",
    "graph_json_path = \"gemfield.json\"\n",
    "with open(graph_json_path, 'w') as fo:\n",
    "    fo.write(graph)\n",
    "\n",
    "param_path = \"gemfield.params\"\n",
    "with open(param_path, 'wb') as fo:\n",
    "    fo.write(relay.save_param_dict(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from PIL import ImageDraw\n",
    "import time\n",
    "import sys, os\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_engine(onnx_file_path, engine_file_path=\"\"):\n",
    "    \"\"\"Attempts to load a serialized engine if available, otherwise builds a new TensorRT engine and saves it.\"\"\"\n",
    "    def build_engine(shape=[1,3,256,832]):\n",
    "        \"\"\"Takes an ONNX file and creates a TensorRT engine to run inference with\"\"\"\n",
    "#         network_creation_flag = 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_PRECISION)\n",
    "#         network_creation_flag |= 1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "        network_creation_flag = 1\n",
    "        with trt.Builder(TRT_LOGGER) as builder, builder.create_network(network_creation_flag) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "            builder.max_workspace_size = 1 << 30 # 1GB\n",
    "            builder.max_batch_size = 1\n",
    "            # Parse model file\n",
    "            if not os.path.exists(onnx_file_path):\n",
    "                print('ONNX file {} not found, please run yolov3_to_onnx.py first to generate it.'.format(onnx_file_path))\n",
    "                exit(0)\n",
    "            print('Loading ONNX file from path {}...'.format(onnx_file_path))\n",
    "            with open(onnx_file_path, 'rb') as model:\n",
    "                if not parser.parse(model.read()):\n",
    "                    for error in range(parser.num_errors):\n",
    "                        print(parser.get_error(error))\n",
    "                print('Beginning ONNX file parsing')\n",
    "                res = parser.parse(model.read())\n",
    "                print(res)\n",
    "#             network.get_input(0).shape = shape\n",
    "            last_layer = network.get_layer(network.num_layers - 1)\n",
    "            network.mark_output(last_layer.get_output(0))\n",
    "            print('Completed parsing of ONNX file')\n",
    "            print('Building an engine from file {}; this may take a while...'.format(onnx_file_path))\n",
    "            engine = builder.build_cuda_engine(network)\n",
    "            print(\"Completed creating Engine\")\n",
    "            with open(engine_file_path, \"wb\") as f:\n",
    "                buf = engine.serialize()\n",
    "                f.write(buf)\n",
    "            return engine\n",
    "\n",
    "    if os.path.exists(engine_file_path):\n",
    "        # If a serialized engine exists, use it instead of building an engine.\n",
    "        print(\"Reading engine from file {}\".format(engine_file_path))\n",
    "        with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "            return runtime.deserialize_cuda_engine(f.read())\n",
    "    else:\n",
    "        return build_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_file_path = os.path.join(\"/work\", \n",
    "                          \"garin0115\", \n",
    "                          \"models\", \n",
    "                          \"resnet18_256x832\", \n",
    "                          \"models\", \n",
    "                          \"weights_19\", \n",
    "                          \"resnet18.onnx\")\n",
    "engine_file_path = \"resnet18.trt\"\n",
    "input_image_path = \"./assets/test_image.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ONNX file from path /work/garin0115/models/resnet18_256x832/models/weights_19/resnet18.onnx...\n",
      "Beginning ONNX file parsing\n",
      "True\n",
      "Completed parsing of ONNX file\n",
      "Building an engine from file /work/garin0115/models/resnet18_256x832/models/weights_19/resnet18.onnx; this may take a while...\n",
      "Completed creating Engine\n"
     ]
    }
   ],
   "source": [
    "engine = get_engine(onnx_file_path, engine_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    \"\"\"Create a TensorRT engine for ONNX-based YOLOv3-608 and run inference.\"\"\"\n",
    "\n",
    "    # Try to load a previously generated YOLOv3-608 network graph in ONNX format:\n",
    "    onnx_file_path = 'yolov3-608.onnx'\n",
    "    engine_file_path = \"yolov3-608.trt\"\n",
    "    input_image_path = \"./images/b.jpg\"\n",
    "\n",
    "    # Two-dimensional tuple with the target network's (spatial) input resolution in HW ordered\n",
    "    input_resolution_yolov3_HW = (608, 608)\n",
    "\n",
    "    # Create a pre-processor object by specifying the required input resolution for YOLOv3\n",
    "    preprocessor = PreprocessYOLO(input_resolution_yolov3_HW)\n",
    "\n",
    "    # Load an image from the specified input path, and return it together with  a pre-processed version\n",
    "    image_raw, image = preprocessor.process(input_image_path)\n",
    "\n",
    "    # Store the shape of the original input image in WH format, we will need it for later\n",
    "    shape_orig_WH = image_raw.size\n",
    "\n",
    "    # Output shapes expected by the post-processor\n",
    "    output_shapes = [(1, 255, 19, 19), (1, 255, 38, 38), (1, 255, 76, 76)]\n",
    "    # output_shapes = [(1, 255, 13, 13), (1, 255, 26, 26), (1, 255, 52, 52)]\n",
    "\n",
    "    # Do inference with TensorRT\n",
    "    trt_outputs = []\n",
    "    a = torch.cuda.FloatTensor()\n",
    "    average_inference_time = 0\n",
    "    average_yolo_time = 0\n",
    "    counter = 10\n",
    "    with get_engine(onnx_file_path, engine_file_path) as engine, engine.create_execution_context() as context:\n",
    "        inputs, outputs, bindings, stream = common.allocate_buffers(engine)\n",
    "        while counter:\n",
    "            # Do inference\n",
    "            print('Running inference on image {}...'.format(input_image_path))\n",
    "            # Set host input to the image. The common.do_inference function will copy the input to the GPU before executing.\n",
    "            inference_start = time.time()\n",
    "            inputs[0].host = image\n",
    "            trt_outputs = common.do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "            inference_end = time.time()\n",
    "            inference_time = inference_end-inference_start\n",
    "            average_inference_time = average_inference_time + inference_time\n",
    "            print('inference time : %f' % (inference_end-inference_start))\n",
    "\n",
    "            # Do yolo_layer with pytorch\n",
    "            inp_dim = 608\n",
    "            num_classes = 80\n",
    "            CUDA = True\n",
    "            yolo_anchors = [[(116, 90), (156, 198), (373, 326)],\n",
    "                            [(30, 61),  (62, 45),   (59, 119)],\n",
    "                            [(10, 13),  (16, 30),   (33, 23)]]\n",
    "            write = 0\n",
    "            yolo_start = time.time()\n",
    "            for output, shape, anchors in zip(trt_outputs, output_shapes, yolo_anchors):\n",
    "                output = output.reshape(shape) \n",
    "                trt_output = torch.from_numpy(output).cuda()\n",
    "                trt_output = trt_output.data\n",
    "                trt_output = predict_transform(trt_output, inp_dim, anchors, num_classes, CUDA)\n",
    "\n",
    "                if type(trt_output) == int:\n",
    "                    continue\n",
    "\n",
    "                if not write:\n",
    "                    detections = trt_output\n",
    "                    write = 1\n",
    "\n",
    "                else:\n",
    "                    detections = torch.cat((detections, trt_output), 1)\n",
    "            dets = dynamic_write_results(detections, 0.5, num_classes, nms=True, nms_conf=0.45) #0.008\n",
    "            yolo_end = time.time()\n",
    "            yolo_time = yolo_end-yolo_start\n",
    "            average_yolo_time = average_yolo_time + yolo_time\n",
    "            print('yolo time : %f' % (yolo_end-yolo_start))\n",
    "            print('all time : %f' % (yolo_end-inference_start))\n",
    "            counter = counter -1\n",
    "\n",
    "        average_yolo_time = average_yolo_time/10\n",
    "        average_inference_time = average_inference_time/10\n",
    "        print(\"--------------------------------------------------------\")\n",
    "        print('average yolo time : %f' % (average_yolo_time))\n",
    "        print('average inference time : %f' % (average_inference_time))\n",
    "        print(\"--------------------------------------------------------\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
